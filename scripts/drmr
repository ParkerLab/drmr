#!/usr/bin/env python
# -*- coding: utf-8 -*-

#
# Submit a drmr script to a distributed resource manager
#

from __future__ import print_function

import argparse
import getpass
import os
import re
import sys
import textwrap

import drmr
import drmr.script

HELP = """
    drmr will read configuration from your ~/.drmrc, e.g.:

    {{
        "resource_manager": "slurm",
        "account": "parkerlab",
    }}

    Directives
    ==========

    Your script can specify job control directives in special
    comments starting with "drmr:".

    # drmr:wait

      Drmr by default runs all the script's commands
      concurrently. The wait directive tells drmr to wait for
      any jobs started since the last wait directive, or the
      beginning of the script, to finish.

    # drmr:job

      You can customize the following job parameters:

{job_directives}

      Whatever you specify will apply to all jobs after the directive.

      To revert to default parameters, use:

      # drmr:job default

      To request 4 CPUs, 8GB of memory per processor, and a
      limit of 12 hours of execution time on one node:

      # drmr:job nodes=1 processors=4 processor_memory=8000 time_limit=12:00:00

    Example
    =======

    A complete example script follows:

    #!/bin/bash

    #
    # Example drmr script. It can be run as a normal shell script, or
    # submitted to a resource manager with the drmr command.
    #

    #
    # You can just write commands as you would in any script. Their output
    # will be captured in files by the resource manager.
    #
    echo thing1

    #
    # You can only use flow control within a command; drmr's parser is not
    # smart enough to deal with conditionals, or create jobs for each
    # iteration of a for loop, or anything like that.
    #
    # You can do this, but it will just all happen in a single job:
    #
    for i in $(seq 1 4); do echo thing${{i}}; done

    #
    # Comments are OK.
    #
    echo thing2  # even trailing comments


    #
    # Line continuations are OK.
    #
    echo thing1 \
         thing2 \
         thing3

    #
    # Pipes are OK.
    #
    echo funicular berry harvester | wc -w

    #
    # The drmr wait directive makes subsequent tasks depend on the
    # successful completion of all jobs since the last wait directive or
    # the start of the script.
    #

    # drmr:wait
    echo "And proud we are of all of them."

    #
    # You can specify job parameters:
    #

    # drmr:job nodes=1 processors=4 processor_memory=8000 time_limit=12:00:00
    echo "I got mine but I want more."

    #
    # And revert to the defaults defined by drmr or the resource manager.
    #

    # drmr:job default
    echo "This job feels so normal."

    # drmr:wait
    # drmr:job time_limit=00:15:00
    echo "All done!"

    # And finally, a job is automatically submitted to wait on all the
    # other jobs and report success or failure of the entire script.
    # Its job ID will be printed.

""".format(**{
    'job_directives': '\n'.join('      {}: {}'.format(*i) for i in drmr.JOB_DIRECTIVES.items())
})

def parse_arguments():
    parser = argparse.ArgumentParser(
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description='Submit a drmr script to a distributed resource manager.',
        epilog=textwrap.dedent(HELP)
    )

    parser.add_argument('-j', '--job-name', dest='job_name', required=True, help='The master PBS job name.')
    parser.add_argument('-a', '--flux-account', dest='account', help='The Flux account to be billed for the jobs.')
    parser.add_argument('-m', '--mail-at-finish', dest='mail_at_finish', action='store_true', help='If specified, mail will be sent when all jobs are finished.')
    parser.add_argument('-q', '--flux-queue', dest='queue', help='The Flux queue in which to run the jobs.')

    parser.add_argument('-w', '--wait-list', dest='wait_list', help="A colon-separated list of job IDs that must complete before any of this script's jobs are started.")
    parser.add_argument('input', help='The file containing commands to submit to Flux. Use "-" for stdin.')

    return parser.parse_args()


def make_wait_list_note(wait_list):
    note = ''
    if wait_list:
        note = '\n# wait list:\n#  ' + '\n#  '.join([jid + (job and (' (%s)' % job) or '') for jid, job in wait_list])
    return note


def create_jobs(template_data, commands, wait_list=[], mail_at_finish=False):
    master_job_name = template_data['name']
    all_jobs = []
    prereqs = wait_list[:]
    job_directives = {}
    i = 1
    for command in commands:
        job_name = master_job_name + '.%s' % i

        job_data = template_data.copy()
        job_data.update({
            'job_name': job_name
        })

        directive, args = drmr.script.parse_directive(command)
        if directive:
            if directive == 'wait' and wait_list:
                i += 1
                job_data['notes'] = make_wait_list_note(wait_list)
                job_id = drmr.submit_completion_jobs(job_data, [w[0] for w in wait_list])
                wait_list = [(job_id, job_name + '.success')]
                prereqs = wait_list[:]
            elif directive == 'pbs' and args:
                if args == 'default':
                    job_directives = {}
                else:
                    job_directives = dict([a.split('=', 1) for a in args.split()])
        else:
            i += 1
            job_data.update(job_directives)
            job_data['command'] = command
            if prereqs:
                job_data['dependencies'] = [prereq_id for prereq_id, prereq_name in prereqs]
                job_data['notes'] = make_wait_list_note(prereqs)
            job_file = drmr.create_job_file(job_data)
            job_id = drmr.submit(job_file)
            wait_list.append((job_id, job_name))
            all_jobs.append(job_id)

    completion_data = template_data.copy()
    completion_data['notes'] = make_wait_list_note(wait_list)
    completion_job_id = drmr.submit_completion_jobs(completion_data, [w[0] for w in wait_list], mail_at_finish=mail_at_finish)

    return all_jobs, completion_job_id


if __name__ == '__main__':

    args = parse_arguments()

    config = drmr.load_configuration({'account': args.account, 'destination': args.destination})

    template_data = {
        'account': config['account'],
        'destination': config['queue'],
        'job_name': args.job_name,
        'working_directory': os.path.abspath(os.getcwd()),
    }

    input_file = args.input == '-' and sys.stdin or open(args.input)
    commands = drmr.script.parse_script(input_file.read())

    wait_list = args.wait_list and args.wait_list.split(':') or []
    try:
        all_jobs, completion_job_id = create_jobs(template_data, commands, wait_list, mail_at_finish=args.mail_at_finish)
    except drmr.SubmissionError as e:
        print('\nYour script could not be submitted.')
        print("Command '%s' returned %s." % (' '.join(e.cmd), e.returncode))
        print("Command output was:\n\n%s\n" % e.output)
        sys.exit(1)

    if all_jobs:
        canceller_filename = '%s.cancel' % args.job_name
        with open(canceller_filename, 'w') as canceller:
            canceller.write('#!/bin/sh\n\n')
            for job in all_jobs:
                canceller.write('qdel %s\n' % job)
            canceller.write('qdel %s\n' % completion_job_id)
            os.chmod(canceller_filename, 0o755)

        print(completion_job_id)
    else:
        print('No jobs submitted. Check your script.')
        sys.exit(1)
