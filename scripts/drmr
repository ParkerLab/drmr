#!/usr/bin/env python
# -*- coding: utf-8 -*-

#
# drmr: A tool for submitting pipeline scripts to distributed resource
# managers.
#
# Copyright 2015 The Parker Lab at the University of Michigan
#
# Licensed under Version 3 of the GPL or any later version
#


from __future__ import print_function

import argparse
import copy
import logging
import os
import sys
import textwrap

import drmr
import drmr.script

HELP = """

    Supported resource managers are:

{resource_managers}

    drmr will read configuration from your ~/.drmrc, which must be
    valid JSON. You can specify your resource manager and default
    values for any job parameters listed below.

    Directives
    ==========

    Your script can specify job control directives in special
    comments starting with "drmr:".

    # drmr:wait

      Drmr by default runs all the script's commands
      concurrently. The wait directive tells drmr to wait for
      any jobs started since the last wait directive, or the
      beginning of the script, to complete successfully.

    # drmr:job

      You can customize the following job parameters:

{job_directives}

      Whatever you specify will apply to all jobs after the directive.

      To revert to default parameters, use:

      # drmr:job default

      To request 4 CPUs, 8GB of memory per processor, and a
      limit of 12 hours of execution time on one node:

      # drmr:job nodes=1 processors=4 processor_memory=8000 time_limit=12:00:00

    Example
    =======

    A complete example script follows:

    #!/bin/bash

    #
    # Example drmr script. It can be run as a normal shell script, or
    # submitted to a resource manager with the drmr command.
    #

    #
    # You can just write commands as you would in any script. Their output
    # will be captured in files by the resource manager.
    #
    echo thing1

    #
    # You can only use flow control within a command; drmr's parser is not
    # smart enough to deal with conditionals, or create jobs for each
    # iteration of a for loop, or anything like that.
    #
    # You can do this, but it will just all happen in a single job:
    #
    for i in $(seq 1 4); do echo thing${{i}}; done

    #
    # Comments are OK.
    #
    echo thing2  # even trailing comments


    #
    # Line continuations are OK.
    #
    echo thing1 \\
         thing2 \\
         thing3

    #
    # Pipes are OK.
    #
    echo funicular berry harvester | wc -w

    #
    # The drmr wait directive makes subsequent tasks depend on the
    # successful completion of all jobs since the last wait directive or
    # the start of the script.
    #

    # drmr:wait
    echo "And proud we are of all of them."

    #
    # You can specify job parameters:
    #

    # drmr:job nodes=1 processors=4 processor_memory=8000 time_limit=12:00:00
    echo "I got mine but I want more."

    #
    # And revert to the defaults defined by drmr or the resource manager.
    #

    # drmr:job default
    echo "This job feels so normal."

    # drmr:wait
    # drmr:job time_limit=00:15:00
    echo "All done!"

    # And finally, a job is automatically submitted to wait on all the
    # other jobs and report success or failure of the entire script.
    # Its job ID will be printed.

""".format(**{
    'job_directives': '\n'.join('      {}: {}'.format(*i) for i in drmr.script.JOB_DIRECTIVES.items()),
    'resource_managers': '\n'.join('      {}'.format(name) for name in drmr.RESOURCE_MANAGERS.keys()),
})

def parse_arguments():
    parser = argparse.ArgumentParser(
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description='Submit a drmr script to a distributed resource manager.',
        epilog=textwrap.dedent(HELP)
    )

    parser.add_argument('-a', '--account', dest='account', help='The account to be billed for the jobs.')
    parser.add_argument('-d', '--destination', dest='destination', help='The queue/partition in which to run the jobs.')
    parser.add_argument('--debug', dest='debug', action='store_true', help='Turn on debug-level logging.')
    parser.add_argument('-j', '--job-name', dest='job_name', required=True, help='The job name.')
    parser.add_argument('-m', '--mail-at-finish', dest='mail_at_finish', action='store_true', help='If specified, mail will be sent when all jobs are finished.')
    parser.add_argument('-w', '--wait-list', dest='wait_list', help="A colon-separated list of job IDs that must complete before any of this script's jobs are started.")
    parser.add_argument('input', help='The file containing commands to submit. Use "-" for stdin.')

    return parser.parse_args()


def make_wait_list_note(wait_list):
    note = ''
    if wait_list:
        note = '\n# wait list:\n#  ' + '\n#  '.join([jid + (job and (' (%s)' % job) or '') for jid, job in wait_list])
    return note


def create_jobs(resource_manager, template_data, script, wait_list=[], mail_at_finish=False):
    master_job_name = template_data['job_name']
    all_jobs = []
    prereqs = wait_list[:]
    job_directives = {}
    i = 1
    for line in script:
        job_name = master_job_name + '.%s' % i

        job_data = copy.deepcopy(template_data)
        job_data.update({
            'job_name': job_name
        })

        directive, args = drmr.script.parse_directive(line)
        if directive:
            if directive == 'wait' and wait_list:
                i += 1
                job_data['notes'] = make_wait_list_note(wait_list)
                job_id = resource_manager.submit_completion_jobs(job_data, [w[0] for w in wait_list])
                wait_list = [(job_id, job_name + '.success')]
                prereqs = wait_list[:]
            elif directive == 'job' and args:
                if args == 'default':
                    job_directives = {}
                else:
                    job_directives = dict([a.split('=', 1) for a in args.split()])
        else:
            i += 1
            job_data.update(job_directives)
            job_data['command'] = line
            if prereqs:
                job_data['dependencies'] = {'ok': [prereq_id for prereq_id, prereq_name in prereqs]}
                job_data['notes'] = make_wait_list_note(prereqs)

            job_file = resource_manager.write_job_file(job_data)
            job_id = resource_manager.submit(job_file)
            wait_list.append((job_id, job_name))
            all_jobs.append(job_id)

    completion_data = copy.deepcopy(template_data)
    completion_data['notes'] = make_wait_list_note(wait_list)
    completion_job_id = resource_manager.submit_completion_jobs(completion_data, [w[0] for w in wait_list], mail_at_finish=mail_at_finish)

    return all_jobs, completion_job_id


if __name__ == '__main__':

    args = parse_arguments()

    if args.debug:
        logging.basicConfig(level=logging.DEBUG)

    try:
        config = drmr.load_configuration({'account': args.account, 'destination': args.destination})
    except drmr.ConfigurationError as e:
        print(e, file=sys.stderr)
        sys.exit(1)

    if 'resource_manager' not in config:
        print('Please specify your resource manager in your drmr configuration file.', file=sys.stderr)
        sys.exit(1)

    rm = drmr.get_resource_manager(config['resource_manager'])

    template_data = {
        'account': config['account'],
        'destination': config['destination'],
        'job_name': args.job_name,
        'working_directory': os.path.abspath(os.getcwd()),
    }

    input_file = args.input == '-' and sys.stdin or open(args.input)
    script = drmr.script.parse_script(input_file.read())

    wait_list = args.wait_list and args.wait_list.split(':') or []
    try:
        all_jobs, completion_job_id = create_jobs(rm, template_data, script, wait_list, mail_at_finish=args.mail_at_finish)
    except drmr.SubmissionError as e:
        print('\nYour script could not be submitted.')
        print("Command '%s' returned %s." % (' '.join(e.cmd), e.returncode))
        print("Command output was:\n\n%s\n" % e.output)
        sys.exit(1)

    if all_jobs:
        print(completion_job_id)
    else:
        print('No jobs submitted. Check your script.')
        sys.exit(1)
